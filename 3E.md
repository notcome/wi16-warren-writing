Big data analytics has become an increasingly popular problem-solving approach. Is this a good phenomenon? In academic researches, many people have the concern that the nature of big data analytics—that it is more about correlational descriptions than causal explanations—would have negative impact to human being’s pursuit of the explanation of the universe. Unfortunately, supporters of big data sometimes ignore this type of counterarguments. In the book _Big Data_, Viktor Mayer-Schönberger and Kenneth Cuvier concentrates on the applications  and ramifications of big data in the industry rather than the academia (Mayer-Schönberger et al. 153 – 196). Cesar Hidalgo, though being a professor at MIT, refutes critics of this sort by asking them to see big data’s immediate benefits instead of responding them directly (Hidalgo 150). I hope this essay can handle this question by showing that big data analytics does not necessarily hinder researchers’ pursuit for causal explanations. Results gained from big data analytics are sometimes indispensable for explanatory theories, and such techniques can be handy for many researchers.

Everyone knows that big data analytics can only reveal correlations, not causal explanations (Hidalgo 149). Then, there is a common opposition against it: this technology will “distract” researchers’ focus from explaining our world causally. This does not hold. First of all, researchers are probably the group who loves causal explanations most. When they have to publish a result that only reveals some correlation about a subject, that subject must be nontrivial. However, some progress is better than no progress. If a researcher decides not to publish anything until he or she can give a convincing theory, other researchers will be discouraged from solving that problem, and grants will likely to fly away. From this perspective, applying big data analytics to a field is good for the long term development in that field. Second, big data analytics is not an exclusive approach; it is a tool meant to complement other methods. Continue the above example. After a researcher uses big data techniques to publish some descriptive results, he or she might continue in-depth analysis—after gaining more grants—to obtain some explanatory theories. Next, the academia has a series of efficient institutions in ensuring rigor researches, like peer reviews during the publication process. These institutions can prevent researchers from deviating from causal studies. Last but not the least, the whole society has already developed a strong attachment to causal explanations. This attachment has already existed when Galileo and his peers started modern science by using quantitative method. In fact, it can be traced back to Aristotle’s formal study of logic. Yet what matters is that stories of those ancient thinkers are told over and over again to every child. Thus, it is impossible for us to give up our pursuit for causal explanations.

There is an even tricker counterargument. Applying big data analytics to traditional subjects of science yields many new subjects. For example, machine learning and statistical methods have been two important techniques of natural language processing, an interdisciplinary branch developed from linguistics (Mayer-Schönberger et al. 115). In spite of those new subjects’ real world applications, do they have theoretical contributions to the original fields? If not, is this a waste of human resources, considering the possible breakthroughs in those fields? To understand this question, one can look at the example of natural language processing more closely. Machine translation is currently done by feeding machines with large corpus (Mayer-Schönberger et al. 85). Machine learning algorithms can automatically figure out some enigmatic patterns underlying human languages, possibly involving millions of variables. Substantial progress has been made using this approach. Yet a theoretical linguist would argue that such advance is unhelpful for understanding how the brain works, which is the ultimate goal of studying natural languages. Indeed, the models generated by machine learning are meaningless to human beings—who can understand formulas involving so many variables? Moreover, when some day we finally understand the rules behind our language systems, will anyone be interested in studying those old models? Therefore, a critic of big data analytics can conclude that advances in statistical-based technologies do not help us in understanding the world. Any research effort in these fields, from a long point of view, is a waste of resources.

Nothing is further from the truth. The results obtained in fields “generated” by big data analytics—both experiences accumulated and tools built—can be quite useful when researchers find explanatory answers. We all know that it is Newton who discovered the gravity and explained why our solar system rotates this way. Does this mean that astronomical observations before Newton was useless? After all, with Newton’s discovery we could predict how a planet would move and generate those observations identically. The answer is no, because Newton needed these data to build a possible theory in the first place. After that, Newton also needed other data to verify his theory. In a similar manner, current works in machine translation could also be helpful in explaining how brain works. Scientists cannot say the exact meaning of each variable of a machine-learnt model, but linguists can still find some general patterns about our language capacities. In the future, cognitive scientists can use these experiences to narrow down their searches for possible brain models. Moreover, language machines trained by large corpus can serve as evaluation tools for explaining human brains. Instead of setting up an expensive experiment with real human beings, scientists can first verify their theories using machines. In short, these seemingly *ad hoc* fields—those generated by big data analytics—are actually prerequisites in finding causal explanations. Without efforts in these fields, finding a good explanation would be, if not impossible,  much harder.

Both arguments above separate correlational descriptions predicted by big data analytics from causal explanations, but in fact, big data analytics can *directly* facilitate researchers in discovering causal explanations. The idea is best characterized by a simple example in math. Mathematically, a function is a procedure that given some input yields some output. When analyzing the behavior of a function, mathematicians often plot the graph of that function, even though such a figure cannot constitute any formal proof that can be published. Why do mathematicians still do this? They plot functions because from these graphs, mathematicians can have a general understanding of functions in question in order to pick the right tools. It is interesting that in many cases, these functions are too complex to be plotted by hand. Mathematicians have to use a computer to draw graphs. How similar is this to big data! It is not hard to conceive that today’s social scientists will face data so complex that they cannot analyze by hand. They need big data analytics to have some research directions before conducting any manual analysis. Moreover, social scientists might be able to ask the machine to find interesting phenomena automatically. Only then do they conduct any in-depth case studies. I came up with both examples within a relatively short period of time. It is therefore reasonable for me to believe that, as techniques harnessing big data become more and more sophisticated, the productivity of researchers will increase even more.

Big data is something different from most technical advances. In the past, we could only process a small amount of data which can only reflect some “local” rules. Think an analogy. Ancient dwellers of San Diego would not know what snow was—they never saw them. That was small data. Big data is like a satellite that allows us to see the weather everywhere on this planet. Abstractly, if we know something’s properties “globally” and if given any parameters we can make accurate predictions of that thing, does it really matter whether we know the underlying rules of that thing?

It is tempting to answer no. However, one would never know the implication of a causal explanation, just like no physicist in 1904 could realize the ramification of the mystery feature of light speed. This is the reason why we cannot give up our pursuit of explaining the world. Big data analytics appears to pose a threat to this principle, but in fact it strengthens this principle. Researchers are the least group of people satisfied with merely describing a phenomenon, and when they do so, they must aim for a greater good. The whole society as well as institutions in the academia also protect human beings from discontinuing our desire for explanations. Though there are some *ad hoc* academic fields whose solely purposes are their real world applications, they are in fact indispensable to our future understanding of the world. Moreover, big data analytics can bring immediate benefits to nowadays researches. Consider the significant benefits brought by big data analytics, I would propose to use big data analytics as default strategy in most fields.