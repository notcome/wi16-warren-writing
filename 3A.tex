\documentclass{writing}

\title{3A}
\date{02/22/16}

\begin{document}

\maketitle

The chapter \emph{Risks} is organized around the question of the
negative impacts of big data. There are three of them
(Mayer-Scheönberger and Cukier 151). First, the way we protect privacy
today no longer works. It is hard, if not impossible, to gain consents
from data's producers whenever one wants to make new use of a set of
data (Mayer-Scheönberger and Cukier 153). Second, people are likely to
abandon the presumption of innocence and judge citizens guilty from big
data's predictions (Mayer-Scheönberger and Cukier 161). Last but not the
least, obsession of statistical data leads to failed analysis
(Mayer-Scheönberger and Cukier 166).

In the next chapter \emph{Control}, the authors provided their answers
to the above questions. Since it is tricky to predict the potential use
of a set of data, it should be the data miner's responsibility to ensure
their research doesn't do evil (Mayer-Scheönberger and Cukier 173). As
for the issue of predicting crime, the authors stick to the principle
that people should be held accountable only for what they \emph{have
done} (Mayer-Scheönberger and Cukier 178). This issue also extends to
fields like employment bias, and the authors suggest that one should be
more careful in selecting the prediction algorithm and that predictions
should be disprovable (Mayer-Scheönberger and Cukier 176). At last, the
authors introduce the concept of ``algorithmists'', experts that help
people to eschew the ``dictatorship of data'' (Mayer-Scheönberger and
Cukier 179).

Two themes are interleaved in the chapter \emph{Next}. The first one
discusses the ``paradigm shift'' of the way we approach issues. In the
past, we only had ``small data'' so a rigorous analysis was inevitable
for an acceptable prediction. Now, we can be more bold in approximation
while at the same time consistently outperforming ourselves in the past
(Mayer-Scheönberger and Cukier 189, 195 -- 196). The second one is a bit
more philosophical and related to the issue of ``determinism'': since
everything can be predicted, what is the meaning of life? Two answers
are given. One is that our predictions about the future is inherently
inaccurate---we need our old-fashioned small data analysis
capability---and the other one is that we should utilize the big data to
make the future evolve as desired, rather than following it blindly
(Mayer-Scheönberger and Cukier 197, 195).

Several questions are left unresolved though. When discussing the
``dictatorship of data'', the authors talked about the case of McNamara.
During the Vietnam war, McNamara was the secretary of defense and chose
Vietnam troops' causalities---``body counts''---as an indicator of
progress. The authors criticized McNamara for the war's inefficiency
based on the fact that ``body counts'' reported from the front line was
mostly fabricated, a behavior encouraged by promotion opportunities
(Mayer-Scheönberger and Cukier 165). However, these two things are
unrelated. Even if McNamara chose the right metric, it is not unlikely
that officers in Vietnam also lied. It is like to criticize a student's
rudeness because he or she did bad on exams. Logical issues like this
exist in other places in the discussion of McNamara, which severely
undermines the credibility of the whole book.

The second serious issue is about the concept of algorithmists. The
authors pointed out that one problem of big data is that it is so
complicated that the mechanism behind its result is beyond human's
understandability (Mayer-Scheönberger and Cukier 178). The formulas
given by machine learning are likely to have hundreds variables or even
more. However, the suggestion following immediately is that we should
train experts that can help all sectors---governments, companies,
organizations---understand the predictions generated from big data
(Mayer-Scheönberger and Cukier 178). It seems unlikely to me that such
experts are trainable, and even if they do, the authors should explain
what part of these experts skills, being it math or computer science,
that differentiate their abilities from those of ordinary people.

The third thing I want the authors to discuss more is about people's
``responsibility'' in this new era. The authors discuss at length about
why people should only be punished for actions they have done
(Mayer-Scheönberger and Cukier 178). A question remains discussion: how
much responsibility should a person take for actions he or she has done,
especially if the decision is made by predictions made from big data?
For instance, should the President be punished for a policy he decreed
even if the policy is the joint result by a group of experts who are
facilitated by big data?

\begin{references}
\item
  Mayer-Schönberger, Viktor and Cukier, Kenneth. ``Big Data.'' 2013. Print.
\end{references}

\end{document}
