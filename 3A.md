The chapter _Risks_ is organized around the question of the negative impacts of big data. There are three of them (Mayer-Scheönberger and Cukier 151). First, the way we protect privacy today no longer works. It is hard, if not impossible, to gain consents from data’s producers whenever one wants to make new use of a set of data  (Mayer-Scheönberger and Cukier 153). Second, people are likely to abandon the presumption of innocence and judge citizens guilty from big data’s predictions (Mayer-Scheönberger and Cukier 161). Last but not the least, obsession of statistical data leads to failed analysis  (Mayer-Scheönberger and Cukier 166).

In the next chapter _Control_, the authors provided their answers to the above questions. Since it is tricky to predict the potential use of a set of data, it should be the data miner’s responsibility to ensure their research doesn’t do evil (Mayer-Scheönberger and Cukier 173). As for the issue of predicting crime, the authors stick to the principle that people should be held accountable only for what they *have done* (Mayer-Scheönberger and Cukier 178). This issue also extends to fields like employment bias, and the authors suggest that one should be more careful in selecting the prediction algorithm and that predictions should be disprovable (Mayer-Scheönberger and Cukier 176). At last, the authors introduce the concept of “algorithmists”, experts that help people to eschew the “dictatorship of data” (Mayer-Scheönberger and Cukier 179).

Two themes are interleaved in the chapter _Next_. The first one discusses the “paradigm shift” of the way we approach issues. In the past, we only had “small data” so a rigorous analysis was inevitable for an acceptable prediction. Now, we can be more bold in approximation while at the same time consistently outperforming ourselves in the past (Mayer-Scheönberger and Cukier 189, 195 – 196). The second one is a bit more philosophical and related to the issue of “determinism”: since everything can be predicted, what is the meaning of life? Two answers are given. One is that our predictions about the future is inherently inaccurate—we need our old-fashioned small data analysis capability—and the other one is that we should utilize the big data to make the future evolve as desired, rather than following it blindly (Mayer-Scheönberger and Cukier 197, 195).

Several questions are left unresolved though. When discussing the “dictatorship of data”, the authors talked about the case of McNamara. During the Vietnam war, McNamara was the secretary of defense and chose Vietnam troops’ causalities—“body counts”—as an indicator of progress. The authors criticized McNamara for the war’s inefficiency based on the fact that “body counts” reported from the front line was mostly fabricated, a behavior encouraged by promotion opportunities (Mayer-Scheönberger and Cukier 165).  However, these two things are unrelated. Even if McNamara chose the right metric, it is not unlikely that officers in Vietnam also lied. It is like to criticize a student’s rudeness because he or she did bad on exams. Logical issues like this exist in other places in the discussion of McNamara, which severely undermines the credibility of the whole book.

The second serious issue is about the concept of algorithmists. The authors pointed out that one problem of big data is that it is so complicated that the mechanism behind its result is beyond human’s understandability (Mayer-Scheönberger and Cukier 178). The formulas given by machine learning are likely to have hundreds variables or even more. However, the suggestion following immediately is that we should train experts that can help all sectors—governments, companies, organizations—understand the predictions generated from big data (Mayer-Scheönberger and Cukier 178). It seems unlikely to me that such experts are trainable, and even if they do, the authors should explain what part of these experts skills, being it math or computer science, that differentiate their abilities from those of ordinary people.

The third thing I want the authors to discuss more is about people’s “responsibility” in this new era. The authors discuss at length about why people should only be punished for actions they have done (Mayer-Scheönberger and Cukier 178). A question remains discussion: how much responsibility should a person take for actions he or she has done, especially if the decision is made by predictions made from big data? For instance, should the President be punished for a policy he decreed even if the policy is the joint result by a group of experts who are facilitated by big data?
